Quale fase di Machine Learning consiste nel definire chiaramente l’obiettivo, le variabili di input e le metriche di valutazione di un problema?  
A) Feature Engineering  
B) Model Deployment  
C) Formalizzazione del problema  
D) Hyperparameter Tuning  
Risposta Corretta: C  
Spiegazione: La formalizzazione del problema prevede la definizione degli obiettivi, delle variabili in ingresso e delle metriche per valutare le prestazioni del modello.

Quale tecnica di apprendimento non supervisionato è utilizzata per raggruppare dati simili in insiemi?  
A) Regressione Lineare  
B) K-Means Clustering  
C) Regressione Logistica  
D) Support Vector Machine  
Risposta Corretta: B  
Spiegazione: K-Means è un algoritmo non supervisionato che suddivide i dati in k cluster minimizzando la varianza all’interno di ciascun cluster.

In Spark, quale operazione viene eseguita immediatamente e innesca il calcolo del DAG?  
A) Transformations  
B) Actions  
C) Lazy Evaluations  
D) Persistences  
Risposta Corretta: B  
Spiegazione: Le azioni, come collect() o count(), vengono eseguite immediatamente e avviano l’esecuzione delle trasformazioni registrate.

Quale metrica è comunemente usata per valutare la purezza di un nodo in un albero decisionale?  
A) Coefficiente di Determinazione (R²)  
B) Entropia  
C) Errore Quadratico Medio (MSE)  
D) Silhouette Score  
Risposta Corretta: B  
Spiegazione: L’entropia misura l’incertezza o il disordine in un nodo, ed è usata per selezionare le migliori suddivisioni negli alberi decisionali.

In PCA, quale passaggio è fondamentale prima di calcolare la matrice di covarianza se le variabili hanno scale diverse?  
A) Decomposizione ai valori singolari  
B) Standardizzazione dei dati  
C) Selezione delle componenti  
D) Proiezione dei dati  
Risposta Corretta: B  
Spiegazione: La standardizzazione porta ogni variabile a media zero e deviazione standard uno, essenziale per un corretto calcolo della covarianza.

Quale funzione in Databricks rimuove i file non necessari da una Delta Table?  
A) optimize()  
B) vacuum()  
C) clean()  
D) compact()  
Risposta Corretta: B  
Spiegazione: La funzione vacuum() elimina i file obsoleti o non referenziati in una Delta Table, liberando spazio.

In regressione lineare, come si chiama il termine di errore nel modello \(y = \beta_0 + \beta_1 x + \epsilon\)?  
A) Coefficiente  
B) Intercetta  
C) Residuo  
D) Iperparametro  
Risposta Corretta: C  
Spiegazione: Il residuo (ε) rappresenta la differenza tra il valore osservato e quello predetto dal modello.

Quale tecnica di validazione incrociata suddivide ripetutamente i dati in k sottogruppi per valutare il modello?  
A) Hold-out Validation  
B) Leave-One-Out  
C) K-Fold Cross-Validation  
D) Bootstrap  
Risposta Corretta: C  
Spiegazione: La validazione k-fold suddivide il dataset in k parti e usa ciascuna a turno come test set, migliorando la stima della generalizzazione.

Quale algoritmo di clustering può gestire cluster di forma arbitraria e rilevare outlier basandosi sulla densità?  
A) Agglomerative Clustering  
B) DBSCAN  
C) K-Means  
D) PCA  
Risposta Corretta: B  
Spiegazione: DBSCAN identifica cluster come aree di alta densità e separa i punti rumorosi (outlier).

In regressione logistica, quale funzione viene utilizzata per mappare i risultati su una probabilità tra 0 e 1?  
A) ReLU  
B) Tangente Iperbolica  
C) Sigmoide (Logistica)  
D) Softmax  
Risposta Corretta: C  
Spiegazione: La funzione sigmoide trasforma la combinazione lineare delle feature in un valore compreso tra 0 e 1.

Quale architettura distingue livelli bronze, silver e gold per minimizzare latenza e migliorare qualità?  
A) Lambda Architecture  
B) Medallion Architecture  
C) Kappa Architecture  
D) Microservices Architecture  
Risposta Corretta: B  
Spiegazione: La Medallion Architecture organizza i dati in livelli bronze, silver e gold, migliorando la qualità e minimizzando la latenza attraverso trasformazioni incrementalmente più pulite e affidabili.

Quale metrica è adatta per valutare la qualità di un clustering?  
A) Precision  
B) Recall  
C) F1-Score  
D) Silhouette Score  
Risposta Corretta: D  
Spiegazione: Il Silhouette Score misura quanto un punto è simile al proprio cluster rispetto agli altri.

In un albero decisionale CART, quale criterio viene utilizzato per la regressione?  
A) Indice di Gini  
B) Entropia  
C) Somma dei Quadrati Residui (RSS)  
D) Information Gain  
Risposta Corretta: C  
Spiegazione: CART usa la RSS per valutare la riduzione dell’errore in problemi di regressione.

Quale tecnica permette di ottimizzare gli iperparametri di un modello mediante ricerca su griglia?  
A) Random Search  
B) Grid Search  
C) Bayesian Optimization  
D) Genetic Algorithms  
Risposta Corretta: B  
Spiegazione: Grid Search esplora sistematicamente una griglia di valori di iperparametri per trovare la combinazione ottimale.

Quale metrica valuta la performance in classificazione binaria considerando sia precisione che recall?  
A) Accuracy  
B) Precision  
C) Recall  
D) F1-Score  
Risposta Corretta: D  
Spiegazione: L’F1-Score è la media armonica di precisione e recall, utile quando le classi sono sbilanciate.

In PCA, come si chiamano le direzioni che massimizzano la varianza nei dati?  
A) Centroidi  
B) Autovalori  
C) Componenti Principali  
D) Feature Latenti  
Risposta Corretta: C  
Spiegazione: Le componenti principali sono combinazioni lineari delle variabili originali che catturano la massima varianza.

Quale metodo aiuta a determinare il numero ottimale di cluster in K-Means?  
A) Metodo del Gomito  
B) Silhouette Analysis  
C) Entrambi i precedenti  
D) AIC  
Risposta Corretta: C  
Spiegazione: Il metodo del gomito e l’analisi della silhouette sono tecniche comuni per scegliere k.

Quale algoritmo di classificazione lineare utilizza vettori di supporto e margini massimi?  
A) Perceptron  
B) Decision Tree  
C) SVM Lineare  
D) Naive Bayes  
Risposta Corretta: C  
Spiegazione: Le SVM lineari cercano l’iperpiano che separa classi con margine massimo.

In regressione lineare multipla, quanti coefficienti β vengono stimati per n feature?  
A) n  
B) n+1  
C) n−1  
D) 2n  
Risposta Corretta: B  
Spiegazione: Oltre ai n coefficienti per le feature, si stima anche l’intercetta β₀.

Quale concetto Shannon ha introdotto per misurare l’incertezza in un insieme di dati?  
A) Entropia  
B) Gini  
C) RSS  
D) MSE  
Risposta Corretta: A  
Spiegazione: Claude Shannon definì l’entropia per quantificare l’informazione e l’incertezza nei sistemi di comunicazione.

Quale modello generativo assume indipendenza condizionale tra feature date le classi?  
A) Random Forest  
B) Naive Bayes  
C) KNN  
D) SVM  
Risposta Corretta: B  
Spiegazione: Naive Bayes assume che le feature siano indipendenti l’una dall’altra all’interno di ogni classe.

In regressione, quale tecnica penalizza i coefficienti aggiungendo il termine \(\lambda\sum\beta_i^2\)?  
A) Lasso  
B) Ridge  
C) Elastic Net  
D) Dropout  
Risposta Corretta: B  
Spiegazione: Ridge Regression aggiunge una penalità L2 sui coefficienti per ridurre l’overfitting.

Quale tecnica combina L1 e L2 penalty nella regressione?  
A) Lasso  
B) Ridge  
C) Elastic Net  
D) Dropout  
Risposta Corretta: C  
Spiegazione: Elastic Net mixa punizioni L1 e L2 per ottenere selezione di feature e stabilità.

In un albero decisionale, quale processo evita l’overfitting riducendo le dimensioni dell’albero?  
A) Pre-pruning  
B) Ensemble  
C) Boosting  
D) PCA  
Risposta Corretta: A  
Spiegazione: Il pre-pruning interrompe la crescita dell’albero basandosi su soglie di purità o profondità.

Quale algoritmo ensemble costruisce alberi in sequenza, correggendo gli errori dei precedenti?  
A) Random Forest  
B) Gradient Boosting  
C) Bagging  
D) AdaBoost  
Risposta Corretta: B  
Spiegazione: Gradient Boosting costruisce alberi iterativamente, minimizzando l’errore residuo.

Quale metrica è più sensibile alle classi sbilanciate?  
A) Accuracy  
B) ROC AUC  
C) Precision-Recall AUC  
D) MSE  
Risposta Corretta: C  
Spiegazione: L’area sotto la curva Precision-Recall è più informativa quando le classi positive sono poche.

In reti neurali, quale funzione di attivazione introduce non linearità e soffre del problema dei “morti”?  
A) Sigmoide  
B) ReLU  
C) Tanh  
D) Softmax  
Risposta Corretta: B  
Spiegazione: ReLU imposta a zero valori negativi e può bloccare neuroni che non si attivano più (dead neurons).

Quale algoritmo di ottimizzazione adatta il learning rate individualmente per ogni parametro?  
A) SGD  
B) Adam  
C) Momentum  
D) RMSProp  
Risposta Corretta: B  
Spiegazione: Adam calcola learning rate adattativi basati sulle prime e seconde stime dei gradienti.

In feature selection, quale metodo valuta ogni feature singolarmente per la relazione con la variabile target?  
A) Wrapper  
B) Embedded  
C) Filter  
D) PCA  
Risposta Corretta: C  
Spiegazione: I metodi filter usano test statistici (es. chi-quadrato) per selezionare feature prima del training.

Quale metodo di ensemble media le previsioni di più modelli indipendenti?  
A) Boosting  
B) Bagging  
C) Stacking  
D) Pruning  
Risposta Corretta: B  
Spiegazione: Bagging addestra modelli su campioni bootstrap e prende la media (o maggioranza) delle loro previsioni.

Quale tecnica riduce la dimensionalità preservando le distanze locali tra punti?  
A) PCA  
B) t-SNE  
C) LDA  
D) UMAP  
Risposta Corretta: B  
Spiegazione: t-SNE proietta dati in basso numero di dimensioni preservando vicinanze locali.

Quale criterio di split in Random Forest introduce casualità aggiuntiva?  
A) Scelta del miglior split su tutte le feature  
B) Scelta random di un sottoinsieme di feature  
C) Utilizzo di Gini su tutte le feature  
D) Nessuno  
Risposta Corretta: B  
Spiegazione: Ad ogni nodo RF valuta split solo su un subset casuale di feature per diversificare gli alberi.

In Time Series, quale modello combina autoregressione e media mobile?  
A) ARIMA  
B) Holt-Winters  
C) Prophet  
D) GARCH  
Risposta Corretta: A  
Spiegazione: ARIMA unisce AR(p), differenziazione e MA(q) per modellare serie storiche.

Quale tecnica di oversampling genera nuovi esempi sintetici dalle minoranze?  
A) Random Oversampling  
B) SMOTE  
C) ADASYN  
D) Undersampling  
Risposta Corretta: B  
Spiegazione: SMOTE sintetizza nuovi punti interpolando tra esempi di minoranza vicini.

In NLP, quale rappresentazione convenzionalizza il testo in vettori densi pre-addestrati?  
A) One-Hot Encoding  
B) TF-IDF  
C) Word Embeddings (es. Word2Vec)  
D) Count Vectorizer  
Risposta Corretta: C  
Spiegazione: Word2Vec mappa parole in vettori densi catturando similarità semantica.

Quale metodo di riduzione dell’overfitting nelle reti neurali disattiva casualmente unità durante l’addestramento?  
A) Weight Decay  
B) Dropout  
C) Batch Normalization  
D) Early Stopping  
Risposta Corretta: B  
Spiegazione: Dropout spegne casualmente neuroni per impedire co-adattamenti.

In clustering gerarchico, quale approccio inizia con ogni punto come cluster e unisce iterativamente?  
A) Divisive  
B) Agglomerative  
C) K-Means  
D) DBSCAN  
Risposta Corretta: B  
Spiegazione: L’agglomerative clustering fonde i due cluster più simili fino a formare un unico cluster.

Quale indice misura la bontà di fit di un modello di regressione lineare?  
A) MSE  
B) R²  
C) MAE  
D) RMSE  
Risposta Corretta: B  
Spiegazione: R² indica la percentuale di varianza spiegata dal modello.

In ensemble stacking, cosa viene utilizzato come input per il modello finale di meta-learning?  
A) Dati originali  
B) Predizioni dei modelli base  
C) Residui dei modelli  
D) Iperparametri dei modelli  
Risposta Corretta: B  
Spiegazione: Il meta-learner impara a combinare le predizioni dei base learners per migliorare l’accuratezza.

Quale tecnica di pre-processing rimuove valori estremi lontani dalla distribuzione?  
A) Min-Max Scaling  
B) Winsorizing  
C) Normalizzazione  
D) PCA  
Risposta Corretta: B  
Spiegazione: Winsorizing limita i valori ai percentili scelti per attenuare l’effetto degli outlier.

In classificazione multiclasse, quale generalizzazione della funzione sigmoide viene usata?  
A) ReLU  
B) Softmax  
C) Tanh  
D) Linear  
Risposta Corretta: B  
Spiegazione: Softmax trasforma un vettore di punteggi in una distribuzione di probabilità sulle classi.

Quale tecnica di feature encoding trasforma feature categoriche in colonne binarie?  
A) Label Encoding  
B) One-Hot Encoding  
C) Ordinal Encoding  
D) Embedding  
Risposta Corretta: B  
Spiegazione: One-Hot crea una colonna per ciascuna categoria, settando 1 se presente e 0 altrimenti.

In reinforcement learning, quale meccanismo bilancia esplorazione ed sfruttamento?  
A) Learning Rate  
B) Discount Factor  
C) Epsilon-Greedy  
D) Entropy Regularization  
Risposta Corretta: C  
Spiegazione: Epsilon-Greedy sceglie casualmente un’azione con probabilità ε per esplorare.

Quale metodo di normalizzazione mantiene la forma della distribuzione ma sposta media e varianza?  
A) Min-Max Scaling  
B) Z-Score Standardization  
C) Log Transformation  
D) Robust Scaling  
Risposta Corretta: B  
Spiegazione: La standardizzazione Z-Score porta media a 0 e deviazione standard a 1 mantenendo la forma.

In un autoencoder, quale parte comprime i dati in uno spazio latente di dimensione ridotta?  
A) Decoder  
B) Encoder  
C) Reconstruction Layer  
D) Hidden Layer  
Risposta Corretta: B  
Spiegazione: L’encoder trasforma l’input in un vettore di dimensione inferiore nello spazio latente.

Quale tecnica seleziona feature utilizzando il modello stesso durante l’addestramento?  
A) Filter  
B) Wrapper  
C) Embedded  
D) PCA  
Risposta Corretta: C  
Spiegazione: I metodi embedded integrano la selezione di feature come parte del processo di training (es. Lasso).

Quale metrica per regressione è meno sensibile agli outlier rispetto all’MSE?  
A) MAE  
B) RMSE  
C) R²  
D) RSS  
Risposta Corretta: A  
Spiegazione: MAE calcola l’errore medio assoluto, penalizzando meno gli outlier rispetto all’MSE.

In clustering, quale algoritmo utilizza gerarchie basate sulla densità e rileva cluster a densità variabile?  
A) DBSCAN  
B) HDBSCAN  
C) K-Means  
D) OPTICS  
Risposta Corretta: B  
Spiegazione: HDBSCAN estende DBSCAN permettendo cluster con densità variabile.

Quale metrica combina sensibilità e specificità per valutare un test diagnostico?  
A) Accuracy  
B) ROC AUC  
C) Precision  
D) Recall  
Risposta Corretta: B  
Spiegazione: L’AUC ROC misura la capacità del modello di distinguere tra classi su tutti i threshold.

Quale concetto evita l’eccessivo adattamento ai dati di training fermando l’addestramento tempestivamente?  
A) Dropout  
B) Early Stopping  
C) Regularization  
D) Data Augmentation  
Risposta Corretta: B  
Spiegazione: L’Early Stopping interrompe l’addestramento quando la performance sul validation set non migliora più.  


Il report di classificazione fornisce informazioni su quali metriche?  
A) Accuracy, MSE, AUC  
B) Precision, Recall, F1-Score, Support  
C) R², MSE, MAE  
D) Log-Loss, ROC AUC, Precision  
Risposta Corretta: B  
Spiegazione: Il classification report include precisione, richiamo, F1-score e supporto per ciascuna classe.

Come si calcola la precisione (Precision)?  
A) TP / (TP + FN)  
B) TP / (TP + FP)  
C) TP / (FP + FN)  
D) (TP + TN) / Totale  
Risposta Corretta: B  
Spiegazione: La precisione misura la frazione di veri positivi tra tutte le predizioni positive.

Come si calcola il richiamo (Recall)?  
A) TP / (TP + FN)  
B) TP / (TP + FP)  
C) TN / (TN + FP)  
D) (TP + TN) / Totale  
Risposta Corretta: A  
Spiegazione: Il recall è la percentuale di veri positivi catturati rispetto a tutti i positivi reali.

Che cos’è l’F1-Score?  
A) Media aritmetica di precision e recall  
B) Media geometrica di precision e recall  
C) Media armonica di precision e recall  
D) Differenza tra precision e recall  
Risposta Corretta: C  
Spiegazione: L’F1-score è la media armonica di precisione e recall, bilanciando entrambe le metriche.

Cosa indica il supporto (Support)?  
A) Numero di predizioni corrette  
B) Numero di istanze di ciascuna classe nel test set  
C) Numero di FP per classe  
D) Numero di FN per classe  
Risposta Corretta: B  
Spiegazione: Il supporto mostra quante occorrenze reali di ogni classe sono presenti nel dataset di verifica.

Qual è uno dei vantaggi di C4.5 rispetto a ID3?  
A) Gestione dei dati continui  
B) Meno complessità computazionale  
C) Nessuna potatura  
D) Nessun supporto per valori mancanti  
Risposta Corretta: A  
Spiegazione: C4.5 può suddividere variabili continue trovando il punto di split ottimale.

Cosa utilizza C4.5 per evitare bias verso attributi con molti valori distinti?  
A) Gain Ratio  
B) Entropia  
C) Gini Index  
D) Chi-square  
Risposta Corretta: A  
Spiegazione: Il gain ratio normalizza il guadagno di informazione dividendo per l’entropia del sottoinsieme.

Quale fase riduce l’overfitting in C4.5?  
A) Pre-pruning  
B) Potatura post-costruzione  
C) Aumento del dataset  
D) Cross-validation  
Risposta Corretta: B  
Spiegazione: C4.5 rimuove rami che non migliorano significativamente le prestazioni su un validation set.

In CART, quale criterio si usa per la regressione?  
A) Indice di Gini  
B) Entropia  
C) RSS (Residual Sum of Squares)  
D) Information Gain  
Risposta Corretta: C  
Spiegazione: CART minimizza la somma dei quadrati residui per suddividere i dati nei nodi.

Quale caratteristica è peculiare di CART rispetto a C4.5?  
A) Gestione dei dati continui  
B) Alberi binari sempre  
C) Gain ratio  
D) Nessuna potatura  
Risposta Corretta: B  
Spiegazione: CART costruisce sempre alberi binari, mentre C4.5 può avere più rami.

Cos’è il bootstrap nel Random Forest?  
A) Valutazione delle feature  
B) Campionamento con ripetizione del training set  
C) Potatura degli alberi  
D) Tecnica di pruning  
Risposta Corretta: B  
Spiegazione: Il bootstrap crea diversi sottoinsiemi di dati per ciascun albero.

Come aggrega le previsioni un Random Forest per la classificazione?  
A) Media  
B) Voto di maggioranza  
C) Softmax  
D) Mediana  
Risposta Corretta: B  
Spiegazione: Ogni albero vota per una classe e quella con più voti è la predizione finale.

Cosa misura l’Out-Of-Bag error nel Random Forest?  
A) Accuracy sul training set  
B) Errore sulle istanze non campionate nel bootstrap  
C) Errore sul validation set esterno  
D) Errore su tutte le istanze  
Risposta Corretta: B  
Spiegazione: Il OOB error è stimato sulle istanze non incluse nel campione bootstrap di ciascun albero.

Qual è un vantaggio chiave del Random Forest?  
A) Interpretabilità  
B) Riduce l’overfitting rispetto a un singolo albero  
C) Richiede pochi alberi  
D) Non usa feature selection  
Risposta Corretta: B  
Spiegazione: Combinando più alberi deboli si ottiene un modello più robusto e meno incline a overfitting.

Cosa sono i support vectors in una SVM?  
A) I pesi finali dell’iperpiano  
B) I dati più vicini all’iperpiano di separazione  
C) I padding parameters  
D) I centroidi dei cluster  
Risposta Corretta: B  
Spiegazione: I support vectors definiscono il margine massimo della SVM.

Qual è lo scopo del kernel trick in SVM?  
A) Accelerare il training  
B) Trasformare i dati in uno spazio superiore per separabilità lineare  
C) Ridurre il margine  
D) Eliminare vettori di supporto  
Risposta Corretta: B  
Spiegazione: Il kernel trick proietta i dati in dimensioni più alte senza calcolare esplicitamente le nuove feature.

Cosa massimizza una SVM lineare?  
A) Numero di support vectors  
B) Margine di separazione tra classi  
C) Likelihood dei dati  
D) Entropia  
Risposta Corretta: B  
Spiegazione: La SVM cerca l’iperpiano che massimizza la distanza tra classi diverse.

Quale funzione di perdita è tipica nelle SVM?  
A) Log-loss  
B) Hinge loss  
C) MSE  
D) Cross-entropy  
Risposta Corretta: B  
Spiegazione: La hinge loss penalizza i punti che cadono al di fuori del margine desiderato.

Quale parametro regola il compromesso tra margine e errori in una SVM?  
A) γ (gamma)  
B) C (regularization parameter)  
C) ε (epsilon)  
D) α (alpha)  
Risposta Corretta: B  
Spiegazione: Il parametro C controlla quanto penalizzare gli errori rispetto all’allargare il margine.

Che cos’è una Relevance SVM (RSVM)?  
A) Una SVM con kernel RBF  
B) Una SVM che seleziona un sottoinsieme rilevante di dati  
C) Una SVM multiclasse  
D) Una SVM senza support vectors  
Risposta Corretta: B  
Spiegazione: RSVM riduce il dataset a un reference set per abbattere i costi computazionali mantenendo prestazioni simili.

Quale approccio bayesiano fornisce una distribuzione di probabilità sui parametri del modello?  
A) Metodi frequentisti  
B) Metodi Bayesiani  
C) SVM  
D) Random Forest  
Risposta Corretta: B  
Spiegazione: I metodi bayesiani combinano prior e likelihood per derivare la posterior distribution.

In Bayes, cosa rappresenta la prior distribution?  
A) La likelihood dei dati  
B) La conoscenza iniziale sui parametri prima di osservare i dati  
C) Il valore a posteriori  
D) Il margine  
Risposta Corretta: B  
Spiegazione: La prior riflette le convinzioni iniziali sui parametri del modello.

Qual è la formula del Teorema di Bayes?  
A) P(A|B) = P(A)·P(B)  
B) P(A|B) = P(B|A)·P(A) / P(B)  
C) P(A|B) = P(A|B) / P(B|A)  
D) P(A|B) = P(B|A) + P(A)  
Risposta Corretta: B  
Spiegazione: Il Teorema di Bayes aggiorna la prior con la likelihood divisa per la marginale.

Che cos’è MCMC?  
A) Un modello di clustering  
B) Una catena di Markov Monte Carlo per campionare posteriori  
C) Un metodo di ottimizzazione di SVM  
D) Un ensemble di alberi  
Risposta Corretta: B  
Spiegazione: MCMC genera campioni da distribuzioni complesse usando processi di Markov.

Qual è uno degli algoritmi MCMC più noti?  
A) K-Means  
B) Metropolis-Hastings  
C) Adam  
D) Gradient Boosting  
Risposta Corretta: B  
Spiegazione: Metropolis-Hastings propone nuovi stati e li accetta in base a un criterio di probabilità.

In MCMC, cosa fa Gibbs Sampling?  
A) Usa gradienti per proporre stati  
B) Campiona ogni variabile condizionalmente alle altre  
C) Costruisce un albero di decisione  
D) Aumenta il margine  
Risposta Corretta: B  
Spiegazione: Gibbs Sampling è un caso particolare di Metropolis-Hastings che campiona da condizionali.

In regressione bayesiana, quale distribuzione si applica come prior sui coefficienti β?  
A) Uniforme  
B) Normale  
C) Bernoulli  
D) Poisson  
Risposta Corretta: B  
Spiegazione: Si sceglie spesso una prior normale su β per modellare conoscenza a priori.

Quale metodo si usa per calcolare la posterior predictive distribution?  
A) Calcolo simbolico chiuso  
B) Integrazione della posterior su β  
C) Sostituzione di MAP  
D) SVM  
Risposta Corretta: B  
Spiegazione: La predictive distribution si ottiene integrando la likelihood sui parametri pesati dalla posterior.

Qual è un vantaggio della regressione bayesiana?  
A) Sempre più veloce della regressione OLS  
B) Fornisce una misura esplicita di incertezza nelle predizioni  
C) Non richiede priors  
D) Non usa dati di training  
Risposta Corretta: B  
Spiegazione: La regressione bayesiana restituisce intervalli di credibilità sulle predizioni.

Qual è uno svantaggio dei metodi bayesiani?  
A) Nessuna flessibilità  
B) Complessità computazionale elevata  
C) Nessun trattamento dell’incertezza  
D) Mancanza di interpretabilità  
Risposta Corretta: B  
Spiegazione: Il campionamento MCMC e l’inferenza variazionale possono essere costosi in termini di tempo.

In classificazione bayesiana, cosa assume Naive Bayes sulle feature?  
A) Dipendenza completa  
B) Indipendenza condizionale  
C) Correlazione lineare  
D) Margine massimo  
Risposta Corretta: B  
Spiegazione: Naive Bayes assume che le feature siano indipendenti date le classi.

Quale smoothing è usato per evitare zero-frequency in Naive Bayes?  
A) L2  
B) Laplace  
C) Dropout  
D) Ridge  
Risposta Corretta: B  
Spiegazione: Lo smoothing di Laplace aggiunge una piccola costante per evitare probabilità nulle.

In RSVM, cosa influenza la selezione del reference set?  
A) Margine  
B) Rilevanza di ciascun punto  
C) Precisione  
D) Recall  
Risposta Corretta: B  
Spiegazione: RSVM sceglie punti più informativi per ridurre il carico computazionale.

Quale tecnica bayesiana permette aggiornamenti incrementali?  
A) K-Fold  
B) Batch gradient  
C) Teorema di Bayes  
D) PCA  
Risposta Corretta: C  
Spiegazione: I metodi bayesiani aggiungono nuove evidenze aggiornando la posterior con la nuova likelihood.

Cosa misura il parametro γ in un kernel RBF SVM?  
A) Incertezza a priori  
B) Ampiezza del kernel  
C) Learning rate  
D) Numero di support vectors  
Risposta Corretta: B  
Spiegazione: γ controlla la larghezza del kernel Gaussiano in RBF.

Quale test aiuta a scegliere il numero di cluster in K-Means?  
A) Metodo del gomito  
B) Silhouette Score  
C) Entrambi  
D) Entrambi non si usano  
Risposta Corretta: C  
Spiegazione: Il metodo del gomito e l’analisi silhouette identificano k ottimale.

In Random Forest, cosa misura l’importanza delle feature?  
A) Frequenza di split  
B) Numero di radici  
C) Profondità dell’albero  
D) Caratteristiche mancanti  
Risposta Corretta: A  
Spiegazione: L’importanza è proporzionale a quanto frequentemente e quanto migliora l’impurity uno split su quella feature.

Che cos’è un modello ensemble?  
A) Un singolo albero  
B) Molti modelli combinati  
C) Un solo neurone  
D) Nessuna predizione  
Risposta Corretta: B  
Spiegazione: Gli ensemble uniscono più modelli deboli per aumentare accuratezza e robustezza.

Quale iperparametro regola la penalizzazione in Ridge Regression?  
A) α  
B) λ  
C) C  
D) γ  
Risposta Corretta: B  
Spiegazione: λ controlla la forza della penalità L2 sui coefficienti.

Cos’è SMOTE?  
A) Un metodo di undersampling  
B) Un metodo di oversampling sintetico  
C) Un kernel SVM  
D) Un albero decisionale  
Risposta Corretta: B  
Spiegazione: SMOTE genera nuovi esempi di minoranza interpolando tra vicini.

In t-SNE, cosa preserva principalmente?  
A) Varianza globale  
B) Distanze locali  
C) Margine  
D) Support vectors  
Risposta Corretta: B  
Spiegazione: t-SNE mantiene la struttura delle vicinanze locali quando riduce dimensioni.

Quale tecnica neural evita co-adattamento dei neuroni?  
A) Weight decay  
B) Dropout  
C) BatchNorm  
D) Early stopping  
Risposta Corretta: B  
Spiegazione: Dropout spegne casualmente neuroni per migliorare generalizzazione.

Che cos’è Early Stopping?  
A) Interrompere l’addestramento quando il training loss cresce  
B) Interrompere l’addestramento quando la performance sul validation set non migliora  
C) Aumentare il learning rate  
D) Ridurre batch size  
Risposta Corretta: B  
Spiegazione: Early Stopping previene overfitting fermando l’allenamento al plateau del validation loss.

In variational inference, cosa si approssima?  
A) La posterior distribution  
B) La prior  
C) Il margine  
D) Il supporto  
Risposta Corretta: A  
Spiegazione: VI usa una family più semplice per approssimare la distribuzione posteriore difficile.

Cos’è il Gini Index in un albero decisionale?  
A) Una misura di purezza/nodal impurity  
B) Un margine  
C) Un kernel  
D) Un support vector  
Risposta Corretta: A  
Spiegazione: Gini misura la probabilità di errata classificazione se si pesca un’istanza a caso nel nodo.

Quale tecnica di ensemble combina modelli addestrati sequenzialmente correggendo errori precedenti?  
A) Bagging  
B) Boosting  
C) Stacking  
D) Pruning  
Risposta Corretta: B  
Spiegazione: Boosting costruisce modelli in serie, ciascuno focalizzato sugli errori residui del precedente.

In PCA, perché si standardizzano i dati?  
A) Migliorare il margine  
B) Uniformare scale diverse  
C) Salvare memoria  
D) Ridurre dimensioni  
Risposta Corretta: B  
Spiegazione: La standardizzazione assicura che variabili con scale diverse non distorcano la covarianza.

Che cos’è l’Information Gain?  
A) Riduzione di entropia dopo uno split  
B) Numero di support vectors  
C) Margine  
D) Entropia iniziale  
Risposta Corretta: A  
Spiegazione: L’IG misura quanto uno split riduce l’incertezza (entropia) nei sottoinsiemi.

Quale tecnica sfrutta catene di Markov per esplorare nel sampling?  
A) K-Means  
B) MCMC  
C) PCA  
D) Grid Search  
Risposta Corretta: B  
Spiegazione: MCMC usa catene di Markov per generare campioni dalla distribuzione target.

In Bayesian classification, come si decide la classe finale?  
A) Massima prior  
B) Massima posterior  
C) Massima likelihood  
D) Minima entropia  
Risposta Corretta: B  
Spiegazione: La classificazione bayesiana assegna la classe con la più alta probabilità a posteriori dato l’input.  

